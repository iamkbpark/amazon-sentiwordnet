{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "import logging\n",
      "import pickle\n",
      "import numpy as np\n",
      "from __future__ import division "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Logging definition\n",
      "logger = logging.getLogger('analyzing')\n",
      "logger.setLevel(logging.DEBUG)\n",
      "fh = logging.FileHandler('log/process_ngrams.log')\n",
      "fh.setLevel(logging.DEBUG)\n",
      "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
      "fh.setFormatter(formatter)\n",
      "logger.addHandler(fh)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def normalize(value):\n",
      "    \"\"\"\n",
      "    Normalize % value to 0.0<=value<=1.0\n",
      "    \"\"\"\n",
      "    value = float(value)\n",
      "    if value > 1.0:\n",
      "        return value / 100\n",
      "    else:\n",
      "        return value\n",
      "    \n",
      "# Load Sentiwordnet\n",
      "sentiwordnet = {}\n",
      "with open('data/sentiwordnet/sentiwordnet.tsv', 'rb') as ifile:\n",
      "    reader = csv.reader(ifile , delimiter='\\t')\n",
      "    headers = reader.next()\n",
      "    for row in reader:\n",
      "        # Upload only adjectives and with a specific objectivity threshold\n",
      "        cond1 = True\n",
      "        if cond1:\n",
      "            sentiwordnet[\"%s\" % (row[5])] = {\"pos\": normalize(row[6]), \"neg\": normalize(row[7]), \"obj\": 1.0}\n",
      "logger.info(' %s sentiwords loaded' % (len(sentiwordnet)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:analyzing: 871 sentiwords loaded\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Process each review\n",
      "total_bands = {\"1.0\": 0, \"2.0\": 0, \"3.0\": 0, \"4.0\": 0, \"5.0\": 0}\n",
      "\n",
      "with open('data/output/words_labeled.p', 'rb') as ifile:\n",
      "    words = pickle.load(ifile)\n",
      "    logger.info(' %s labeled words loaded' % (len(words)))\n",
      "    with open('data/output/results.tsv', 'wb') as ofile:\n",
      "        writer = csv.writer(ofile, delimiter='\\t')\n",
      "        writer.writerow([\"word\", \"pos\", \"neg\", \"1.0\", \"2.0\", \"3.0\", \"4.0\", \"5.0\"])\n",
      "                            \n",
      "        for word in words:\n",
      "            for band in words[word]:\n",
      "                total_bands[band] += words[word][band]\n",
      "            n = sum(words[word][i] for i in words[word])\n",
      "\n",
      "            # Random experiment\n",
      "            random_experiment = True\n",
      "            if not random_experiment:\n",
      "                sw_pos = sentiwordnet[word][\"pos\"]\n",
      "                sw_neg = sentiwordnet[word][\"neg\"]\n",
      "            else:\n",
      "                if np.random.uniform(0,1) > 0.5:\n",
      "                    sw_pos = 0.0\n",
      "                    sw_neg = np.random.uniform(0,1)\n",
      "                else:\n",
      "                    sw_neg = 0.0\n",
      "                    sw_pos = np.random.uniform(0,1)\n",
      "                    \n",
      "            # Write row to file\n",
      "            writer.writerow([word, sw_pos, sw_neg, \n",
      "                            words[word][\"1.0\"]/n, words[word][\"2.0\"]/n, words[word][\"3.0\"]/n, \n",
      "                            words[word][\"4.0\"]/n, words[word][\"5.0\"]/n])\n",
      "\n",
      "logger.info(' Bands distribution %s' % (total_bands))       "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:analyzing: 510 labeled words loaded\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:analyzing: Bands distribution {'5.0': 126337, '2.0': 32496, '1.0': 42538, '4.0': 93482, '3.0': 41045}\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Bands probability Analysis "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def acum_probability(data, bands):\n",
      "    \"\"\"\n",
      "    Return accum probability\n",
      "    \"\"\"\n",
      "    n = sum(data[band] for band in data)\n",
      "    if n == 0:\n",
      "        return 0.0\n",
      "    else:\n",
      "        return sum([data[band]/n for band in bands])\n",
      "        \n",
      "    \n",
      "with open('data/output/words_labeled.p', 'rb') as ifile:\n",
      "    words = pickle.load(ifile)\n",
      "    for word in words:\n",
      "        value = acum_probability(words[word], [\"3.0\", \"4.0\", \"5.0\"])\n",
      "        if value >= 0.9:\n",
      "            pass\n",
      "            #print(word,\" \",words[word])\n",
      "            #print(\"\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}